{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GdN8D2vn0BmX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c induction-task"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ4ipfXi8u5a",
        "outputId": "d10f34ce-8225-4cf2-f44d-7170cfd6d7eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading induction-task.zip to /content\n",
            " 97% 194M/201M [00:01<00:00, 196MB/s]\n",
            "100% 201M/201M [00:01<00:00, 182MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_f = zipfile.ZipFile('/content/induction-task.zip', 'r')\n",
        "zip_f.extractall('/content')\n",
        "zip_f.close()"
      ],
      "metadata": {
        "id": "JtSNjDoo8wWp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
      ],
      "metadata": {
        "id": "K8kCGg_09s2I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_dir = \"/content/Data/Train\"\n",
        "new_size = (256,256)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=new_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=new_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pW4AHNJG5QI",
        "outputId": "518b25a3-e579-4f0f-d2a2-ed93e4c75953"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 641 images belonging to 2 classes.\n",
            "Found 160 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "image_folder = \"/content/Data/Train/Real\"\n",
        "output_folder = \"/content/Real_resized\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img_resized = cv2.resize(img, new_size)\n",
        "        cv2.imwrite(os.path.join(output_folder, filename), img_resized)"
      ],
      "metadata": {
        "id": "OgdeICcK-K5V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/Data/Train/AI\"\n",
        "output_folder = \"/content/AI_resized\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img_resized = cv2.resize(img, new_size)\n",
        "        cv2.imwrite(os.path.join(output_folder, filename), img_resized)"
      ],
      "metadata": {
        "id": "iePW2SzCByPG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "image_folder = \"/content/Real_resized\"\n",
        "\n",
        "image_array_list = []\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img_array = np.array(img)\n",
        "        image_array_list.append(img_array)\n",
        "\n",
        "real_array = np.stack(image_array_list)\n",
        "\n",
        "print(f\"Final Shape of Array: {real_array.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP1REmVuCB6n",
        "outputId": "20d6d44a-c9c1-4583-abaa-e1a979fffa77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Shape of Array: (400, 512, 512, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/AI_resized\"\n",
        "\n",
        "image_array_list = []\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img_array = np.array(img)\n",
        "        image_array_list.append(img_array)\n",
        "\n",
        "ai_array = np.stack(image_array_list)\n",
        "\n",
        "print(f\"Final Shape of Array: {ai_array.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHJtZGiVCZ65",
        "outputId": "f30757e3-8d6a-43d3-a0cb-9fede0328baf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Shape of Array: (401, 512, 512, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_ai = np.zeros(len(ai_array))\n",
        "label_real = np.ones(len(real_array))\n",
        "\n",
        "X = np.concatenate((ai_array, real_array), axis=0)\n",
        "Y = np.concatenate((label_ai, label_real), axis=0)\n",
        "\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of Y: {Y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdpTXO_PCpOp",
        "outputId": "ec5f41d5-287a-49ee-bf4d-8b656759f4c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (801, 512, 512, 3)\n",
            "Shape of Y: (801,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=X/255.0"
      ],
      "metadata": {
        "id": "JfVslXML7yCR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(256,256, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(512, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(900, activation='relu'),\n",
        "    Dense(150, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "2qUhIahlEYgE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "ebGS3pOsE3BT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=12,\n",
        "    batch_size=32  # Reduced batch size\n",
        ")\n"
      ],
      "metadata": {
        "id": "soO0ySQrFZYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c62d036e-c9e4-4daf-8244-a9974af4bddd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-46-040f67f7949b>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nOut of memory while trying to allocate 1959863928 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_35430]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-040f67f7949b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m  \u001b[0;31m# Reduced batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-46-040f67f7949b>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nOut of memory while trying to allocate 1959863928 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_35430]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D99xRS2L6zH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "metadata": {
        "id": "zjO8nyC2Fj4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "image_folder = \"/content/Data/Test\"\n",
        "output_folder = \"/content/Test_resized\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "new_size=(256,256)\n",
        "a=0\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Check if image was loaded successfully\n",
        "        if img is None:\n",
        "            print(f\"Error loading image: {img_path}\")\n",
        "            continue  # Skip to the next image\n",
        "\n",
        "        img_resized = cv2.resize(img, new_size)\n",
        "        cv2.imwrite(os.path.join(output_folder, filename), img_resized)\n",
        "        a+=1\n",
        "\n",
        "print(\"All images have been reshaped and saved.\")\n",
        "print(a)"
      ],
      "metadata": {
        "id": "wR4LbShrJU6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/Test_resized\"\n",
        "\n",
        "def natural_sort_key(filename):\n",
        "    import re\n",
        "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', filename)]\n",
        "\n",
        "image_filenames = sorted(\n",
        "    [f for f in os.listdir(image_folder) if f.endswith((\".jpg\", \".png\", \".jpeg\"))],\n",
        "    key=natural_sort_key\n",
        ")\n",
        "\n",
        "image_array_list = []\n",
        "image_size=(256,256)\n",
        "for filename in image_filenames:\n",
        "    img_path = os.path.join(image_folder, filename)\n",
        "    img = Image.open(img_path).resize(image_size)\n",
        "    img_array = np.array(img)\n",
        "    image_array_list.append(img_array)\n",
        "\n",
        "test_array = np.stack(image_array_list)\n",
        "\n",
        "print(f\"Final array shape: {test_array.shape}\")\n"
      ],
      "metadata": {
        "id": "uS0DAAtAH4XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_array=test_array/255.0\n",
        "prediction = model.predict(test_array)"
      ],
      "metadata": {
        "id": "KPqL3DSNJQRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "image_ids = [f'image_{i+1}' for i in range(200)]\n",
        "\n",
        "labels = ['Real' if pred > 0.5 else 'AI' for pred in prediction]\n",
        "\n",
        "if len(image_ids) != len(labels):\n",
        "    print(\"Error: Mismatch between number of image IDs and predictions.\")\n",
        "else:\n",
        "    with open('submission.csv', mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        writer.writerow(['Id', 'Label'])\n",
        "\n",
        "        for img_id, label in zip(image_ids, labels):\n",
        "            writer.writerow([img_id, label])\n",
        "\n",
        "    print(\"Submission file created: submission.csv\")"
      ],
      "metadata": {
        "id": "gGKaw48xKMYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ykCyQceyKSek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
