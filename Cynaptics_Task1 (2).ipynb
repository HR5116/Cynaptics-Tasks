{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GdN8D2vn0BmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38a62ab-7d51-402c-9c80-2466a8f8ab3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 65 Jan 17 18:20 /root/.kaggle/kaggle.json\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -l ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d hrwarrior/iinduction-task-2025"
      ],
      "metadata": {
        "id": "oF9PQyG2h0RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddfe7c1-fc28-4b6a-e6cd-ddbf475198e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/hrwarrior/iinduction-task-2025\n",
            "License(s): CC0-1.0\n",
            "Downloading iinduction-task-2025.zip to /content\n",
            " 97% 139M/144M [00:02<00:00, 31.0MB/s]\n",
            "100% 144M/144M [00:02<00:00, 54.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c induction-task-2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ4ipfXi8u5a",
        "outputId": "c81119ee-ba78-4478-ffc6-466e9968c929"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading induction-task-2025.zip to /content\n",
            " 83% 67.0M/80.9M [00:00<00:00, 126MB/s]\n",
            "100% 80.9M/80.9M [00:00<00:00, 137MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_f = zipfile.ZipFile('/content/iinduction-task-2025.zip', 'r')\n",
        "zip_f.extractall('/content')\n",
        "zip_f.close()"
      ],
      "metadata": {
        "id": "JtSNjDoo8wWp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_f = zipfile.ZipFile('/content/induction-task-2025.zip', 'r')\n",
        "zip_f.extractall('/content')\n",
        "zip_f.close()"
      ],
      "metadata": {
        "id": "3q7CrPvsh9WF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow_heif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TanMlAQddBUS",
        "outputId": "70cc5c33-fa0c-4c3a-d740-c957e96d7940"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow_heif\n",
            "  Downloading pillow_heif-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.11/dist-packages (from pillow_heif) (11.1.0)\n",
            "Downloading pillow_heif-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow_heif\n",
            "Successfully installed pillow_heif-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "K8kCGg_09s2I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_dir = \"/content/New_Data\"\n",
        "new_size = (256,256)\n",
        "batch_size = 25\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.20)\n",
        "\n",
        "def image_loader(img_path):\n",
        "    try:\n",
        "        with open(img_path, \"rb\") as f:\n",
        "            img = Image.open(f).convert('RGB').resize(new_size)\n",
        "            return img\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"Error loading image: {img_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error loading image: {img_path}, Error: {e}\")\n",
        "        return None\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=new_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=new_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pW4AHNJG5QI",
        "outputId": "1040d0dc-b6f3-4c2a-c45e-7b2f40b91bc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 474 images belonging to 2 classes.\n",
            "Found 118 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/New_Data/Real\"\n",
        "output_folder = \"/content/Real_resized\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img_resized = cv2.resize(img, new_size)\n",
        "        cv2.imwrite(os.path.join(output_folder, filename), img_resized)"
      ],
      "metadata": {
        "id": "OgdeICcK-K5V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/New_Data/AI\"\n",
        "output_folder = \"/content/AI_resized\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Error loading image: {img_path}\")\n",
        "            continue\n",
        "        img_resized = cv2.resize(img, new_size)\n",
        "        cv2.imwrite(os.path.join(output_folder, filename), img_resized)"
      ],
      "metadata": {
        "id": "iePW2SzCByPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51c7812-70f1-4e41-b6f2-78936cb6f819"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image: /content/New_Data/AI/image_326.jpg\n",
            "Error loading image: /content/New_Data/AI/image_530.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "image_folder = \"/content/Real_resized\"\n",
        "\n",
        "image_array_list = []\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = Image.open(img_path).resize((256, 256))\n",
        "        img_array = np.array(img)\n",
        "        image_array_list.append(img_array)\n",
        "\n",
        "real_array = np.stack(image_array_list)\n",
        "print(f\"Final Shape of Array: {real_array.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP1REmVuCB6n",
        "outputId": "00be9bde-7739-49c1-b7dd-8e1e53e82807"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Shape of Array: (296, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_folder = \"/content/AI_resized\"\n",
        "\n",
        "image_array_list = []\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img_array = np.array(img)\n",
        "        image_array_list.append(img_array)\n",
        "\n",
        "ai_array = np.array(image_array_list)\n",
        "print(f\"Final Shape of Array: {ai_array.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHJtZGiVCZ65",
        "outputId": "8fb692ec-2192-4cab-c40c-7d06b306a0c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Shape of Array: (294, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_ai = np.zeros(len(ai_array))\n",
        "label_real = np.ones(len(real_array))\n",
        "\n",
        "X = np.concatenate((ai_array, real_array), axis=0)\n",
        "Y = np.concatenate((label_ai, label_real), axis=0)\n",
        "\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of Y: {Y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdpTXO_PCpOp",
        "outputId": "acf7e8af-b37f-4314-d13a-25a0ee74af03"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (590, 256, 256, 3)\n",
            "Shape of Y: (590,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential([\n",
        "    Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(512, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    GlobalAveragePooling2D(),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "2qUhIahlEYgE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "ebGS3pOsE3BT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=11,\n",
        "    batch_size=27\n",
        ")"
      ],
      "metadata": {
        "id": "soO0ySQrFZYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bcb6ae-b24e-465b-d11f-e5167a5499c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 5/19\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 393ms/step - accuracy: 0.4675 - loss: 1.3944"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D99xRS2L6zH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "metadata": {
        "id": "zjO8nyC2Fj4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5669a526-2b43-4ecf-cc04-67557596e377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 614ms/step - accuracy: 0.4681 - loss: 0.9813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9422107338905334, 0.504273533821106]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/Test_Images\"\n",
        "output_folder = \"/content/Test_resized\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "new_size=(256,256)\n",
        "a=0\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        img_resized = cv2.resize(img, new_size)\n",
        "        cv2.imwrite(os.path.join(output_folder, filename), img_resized)\n",
        "        a+=1\n",
        "\n",
        "print(\"All images have been reshaped and saved.\")\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR4LbShrJU6R",
        "outputId": "1c57bd03-4415-42a6-abd9-fc155522e5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images have been reshaped and saved.\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/Test_resized\"\n",
        "\n",
        "def natural_sort_key(filename):\n",
        "    import re\n",
        "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', filename)]\n",
        "\n",
        "image_filenames = sorted(\n",
        "    [f for f in os.listdir(image_folder) if f.endswith((\".jpg\", \".png\", \".jpeg\"))],\n",
        "    key=natural_sort_key\n",
        ")\n",
        "\n",
        "image_array_list = []\n",
        "image_size=(256,256)\n",
        "for filename in image_filenames:\n",
        "    img_path = os.path.join(image_folder, filename)\n",
        "    img = Image.open(img_path).resize(image_size)\n",
        "    img_array = np.array(img)\n",
        "    image_array_list.append(img_array)\n",
        "\n",
        "test_array = np.stack(image_array_list)\n",
        "\n",
        "print(f\"Final array shape: {test_array.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS0DAAtAH4XT",
        "outputId": "1d671758-9fc3-40ee-c0d5-b59920585d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final array shape: (200, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_array=test_array/255.0\n",
        "prediction = model.predict(test_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPqL3DSNJQRX",
        "outputId": "2bd83212-a615-4097-898a-cbc737a3daf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7abcadcba170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "\n",
        "image_ids = [f'image_{i}' for i in range(200)]\n",
        "\n",
        "labels = ['Real' if pred > 0.5 else 'AI' for pred in prediction]\n",
        "\n",
        "if len(image_ids) != len(labels):\n",
        "    print(\"Error: Mismatch between number of image IDs and predictions.\")\n",
        "else:\n",
        "    with open('Final.csv', mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        writer.writerow(['Id', 'Label'])\n",
        "\n",
        "        for img_id, label in zip(image_ids, labels):\n",
        "            writer.writerow([img_id, label])\n",
        "\n",
        "    print(\"Submission file created: Final.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGKaw48xKMYe",
        "outputId": "12e66657-bd23-4778-9f9c-e78c32c62113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: Final.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!kaggle competitions submit -c induction-task-2025 -f Final.csv -m \"Message\""
      ],
      "metadata": {
        "id": "ykCyQceyKSek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20360931-19e9-43da-91b1-8073260f0d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 3.03k/3.03k [00:00<00:00, 4.81kB/s]\n",
            "Successfully submitted to Gradient Hunt 2.0: The Saga "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hwsyqK7lu7D6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}